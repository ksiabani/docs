# ğŸ§ª Running AIandMe Experiments - Contextual AI Pen-Testing  

> AIandMe **experiments** function similarly to **penetration testing in cybersecurity**â€”but instead of testing software vulnerabilities, we test how well a GenAI assistant aligns with its **expected behavior and business scope**.  

> Each experiment **simulates adversarial interactions** to evaluate how the AI assistant handles **unexpected or potentially unsafe inputs**.  

## **ğŸ› ï¸ How AIandMe Experiments Work**  

The AIandMe **testing pipeline** follows these structured steps:  

ğŸ“Œ **Experiment Workflow:**  
![Experiment Pipeline](./download_(1).png)  

---

## **ğŸš€ Running an Experiment**  

Once your **project is set up**, you can **start an experiment** by following these steps:  

### **Create an Experiment**  
1. Go to the **Experiments** page and click **"Create Experiment"**.  
   ![Create Experiment](./Screenshot_2025-01-26_at_14.18.21.png)  
2. Fill in the **experiment details** (name, description, etc.).  
3. Select the **model provider** for LLM-as-a-Judge evaluations.  
4. Configure the **GenAI assistant integration** for testing.  
5. Click **"Create"** to launch the experiment.  

---

## **âš¡ Experiment Execution: Step-by-Step**  

Once started, the experiment runs **automatically in the background**, executing the following steps:

### **ğŸ”¹ Step 1: Adversarial Data Generation**  
- If no dataset exists for the **current project scope**, AIandMe **auto-generates adversarial synthetic prompts**.  
- These prompts simulate **real-world edge cases** and **unexpected user interactions**.  

### **ğŸ”¹ Step 2: AI Assistant Testing**  
- Each **adversarial prompt** is sent to the **GenAI assistant**.  
- The response is **evaluated** against the **expected business behavior**.  
- AIandMeâ€™s **LLM-as-a-Judge** assigns a **pass/fail verdict** based on predefined guidelines.  

### **ğŸ”¹ Step 3: Experiment Completion & Insights**  
- AIandMe **compiles a final report** with:  
  ğŸ” **Findings from the experiment**  
  ğŸ“Š **Detailed logs for auditing & human review**  
  ğŸ›  **Recommendations for improving AI robustness**  

ğŸ“Œ **Experiment Completion Overview:**  
![Experiment Completion](./Screenshot_2025-01-26_at_15.53.32.png)  

---

## **ğŸ”— Next Steps**
- âš–ï¸ **[Understanding LLM-as-a-Judge](llm_as_a_judge)**  
- ğŸ”¥ **[AIandMe Firewall: Safe AI Responses](firewall)**  
- âš™ï¸  **[AIandMe Integration](aiandme_integration)**  

---

ğŸ’¡ Need help? Check out **[FAQs](faqs)** or **[Join the AIandMe Community](community)**.
