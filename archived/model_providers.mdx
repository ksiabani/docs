---
title: "🔌 Model Providers & Integration"
description: "Connect and configure AI model providers for experiments and LLM-as-a-Judge evaluation"
breadcrumb: false
---

# 🔌 Model Providers & Integration

Model providers are the **foundation** of ai+me's AI security testing capabilities. They power both your **experiments** and the **LLM-as-a-Judge** evaluation system. Think of them as the **AI engines** that analyze your AI applications for vulnerabilities, test responses, and evaluate security compliance.

## 🎯 What are Model Providers?

Model providers in ai+me are **external AI services** that provide the computational power for:

- **🧪 Experiment Execution**: Running security tests against your AI applications
- **⚖️ LLM-as-a-Judge**: Evaluating AI responses for safety and compliance
- **🛡️ Firewall Analysis**: Real-time security assessment of user requests
- **📊 Result Evaluation**: Analyzing test outcomes and generating insights

### 🔍 **Key Concepts**

#### **Provider Integration**
- **API Connectivity**: Secure connection to external AI services
- **Authentication**: API key management and validation
- **Model Selection**: Choose specific AI models for different tasks
- **Configuration Management**: Centralized provider settings

#### **Multi-Provider Support**
- **Flexibility**: Use different providers for different use cases
- **Redundancy**: Backup providers for high availability
- **Cost Optimization**: Choose providers based on cost and performance
- **Geographic Distribution**: Select providers for regional compliance

#### **Security & Compliance**
- **Secure Storage**: Encrypted API key management
- **Access Control**: Organization-level provider management
- **Audit Trails**: Complete provider usage logging
- **Compliance**: Support for enterprise security requirements

## 🏗️ How Model Providers Work

Model providers integrate with ai+me through a **standardized interface** that enables seamless AI security testing:

### 📊 **Provider Architecture**

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   ai+me         │    │   Model         │    │   External      │
│   Platform      │───▶│   Provider      │───▶│   AI Service    │
│                 │    │                 │    │                 │
│ • Experiments   │    │ • API Gateway   │    │ • OpenAI        │
│ • Firewall      │    │ • Auth Manager  │    │ • Azure OpenAI  │
│ • Evaluations   │    │ • Model Router  │    │ • Claude        │
│ • Analytics     │    │ • Response      │    │ • Gemini        │
│                 │    │   Handler       │    │                 │
└─────────────────┘    └─────────────────┘    └─────────────────┘
                                │
                                ▼
                       ┌─────────────────┐
                       │   Results &     │
                       │   Analytics     │
                       │                 │
                       │ • Test Results  │
                       │ • Evaluations   │
                       │ • Performance   │
                       │ • Cost Tracking │
                       └─────────────────┘
```

### 🔄 **Integration Flow**

1. **Provider Setup**: Configure API credentials and model selection
2. **Request Routing**: ai+me routes requests to appropriate providers
3. **Authentication**: Secure API key validation and management
4. **Model Execution**: AI models process security tests and evaluations
5. **Response Handling**: Results are processed and analyzed
6. **Analytics**: Performance and cost metrics are tracked

## 🚀 Setting Up Model Providers

### **Step 1: Access Model Provider Settings**

1. Navigate to your **ai+me Dashboard**
2. Go to **Settings** → **Model Providers**
3. View available providers and their status

### **Step 2: Choose Your Provider**

ai+me supports multiple model providers with different capabilities:

#### **Currently Supported Providers**

##### **OpenAI**
- **Models**: GPT-4, GPT-4 Turbo, GPT-3.5 Turbo
- **Use Cases**: General AI security testing, LLM-as-a-Judge evaluation
- **Features**: High accuracy, extensive model selection
- **Best For**: Production environments, comprehensive testing

##### **Azure OpenAI**
- **Models**: GPT-4, GPT-3.5 Turbo (Azure-hosted)
- **Use Cases**: Enterprise deployments, compliance requirements
- **Features**: Enterprise security, regional compliance
- **Best For**: Enterprise environments, data residency requirements

#### **Coming Soon Providers**

- **Grok**: Advanced reasoning and analysis
- **Claude**: Anthropic's safety-focused models
- **DeepSeek**: Specialized security and compliance
- **Gemini**: Google's multimodal AI capabilities

### **Step 3: Configure Provider Settings**

#### **OpenAI Configuration**

1. **Click "Set Up"** next to OpenAI provider
2. **Enter API Key**: Your OpenAI API key from [OpenAI Platform](https://platform.openai.com/api-keys)
3. **Select Model**: Choose from available models (default: gpt-4o)
4. **Validate Configuration**: Test the connection
5. **Save Settings**: Complete the setup

**API Key Requirements:**
- Must start with `sk-`
- Minimum 20 characters long
- Valid and active OpenAI account

#### **Azure OpenAI Configuration**

1. **Click "Set Up"** next to Azure OpenAI provider
2. **Enter Endpoint URL**: Your Azure OpenAI endpoint
   - Format: `https://your-resource.openai.azure.com/openai/deployments/your-deployment-name/chat/completions?api-version=2024-02-15-preview`
   - Must include `api-version` parameter
   - Must be a valid Azure domain
3. **Enter API Key**: Your Azure OpenAI API key
4. **Select Model**: Choose your deployed model
5. **Validate Configuration**: Test the connection
6. **Save Settings**: Complete the setup

**Endpoint Requirements:**
- Must be a valid HTTPS URL
- Must end with `.azure.com`
- Must include `api-version` parameter
- Must point to a valid Azure OpenAI resource

### **Step 4: Test Your Configuration**

After setup, ai+me will:
- **Validate Credentials**: Test API key and endpoint connectivity
- **Verify Model Access**: Ensure selected models are available
- **Test Integration**: Run a basic connectivity test
- **Confirm Setup**: Display success confirmation

## 🔧 Managing Model Providers

### **Provider Dashboard**

#### **Provider Status**
- **Active**: Provider is configured and ready for use
- **Inactive**: Provider needs configuration
- **Error**: Configuration issues detected
- **Testing**: Provider is being validated

#### **Provider Information**
- **Provider Name**: Display name and type
- **API Key**: Masked API key for security
- **Creation Date**: When provider was added
- **Last Updated**: Last configuration change
- **Usage Statistics**: Request counts and performance

### **Provider Actions**

#### **Edit Provider**
1. **Click "Edit"** in provider dropdown menu
2. **Update API Key**: Enter new API key if needed
3. **Modify Settings**: Change model selection or configuration
4. **Save Changes**: Apply updated settings

#### **Revoke Provider**
1. **Click "Revoke"** in provider dropdown menu
2. **Confirm Action**: Acknowledge the revocation
3. **Remove Access**: API key is invalidated
4. **Update Status**: Provider marked as inactive

### **Provider Management Best Practices**

#### **Security**
- **Regular Key Rotation**: Update API keys periodically
- **Access Monitoring**: Monitor provider usage and costs
- **Credential Protection**: Never share API keys
- **Audit Logging**: Track provider configuration changes

#### **Performance**
- **Model Selection**: Choose appropriate models for your use case
- **Cost Optimization**: Monitor usage and optimize for cost
- **Load Balancing**: Use multiple providers for high availability
- **Regional Selection**: Choose providers for geographic compliance

## 📊 Provider Analytics & Monitoring

### **Usage Analytics**

#### **Request Metrics**
- **Total Requests**: Number of requests processed
- **Success Rate**: Percentage of successful requests
- **Response Time**: Average and peak response times
- **Error Rate**: Percentage of failed requests

#### **Cost Tracking**
- **Token Usage**: Number of tokens consumed
- **Cost per Request**: Average cost per API call
- **Monthly Spend**: Total cost for the billing period
- **Cost Trends**: Historical cost analysis

### **Performance Monitoring**

#### **Response Time Analysis**
- **Average Latency**: Mean response time across requests
- **Peak Latency**: Maximum response time observed
- **P95 Latency**: 95th percentile response time
- **Timeout Analysis**: Requests that exceed time limits

#### **Error Analysis**
- **Error Types**: Categories of errors encountered
- **Error Frequency**: How often different errors occur
- **Error Impact**: Effect on experiment completion
- **Resolution Time**: Time to resolve provider issues

### **Provider Health**

#### **Availability Monitoring**
- **Uptime**: Provider service availability
- **Downtime**: Service interruption periods
- **Recovery Time**: Time to restore service
- **Health Checks**: Regular connectivity validation

#### **Quality Metrics**
- **Response Quality**: Accuracy of AI responses
- **Consistency**: Reliability of model outputs
- **Bias Detection**: Identification of model biases
- **Safety Compliance**: Adherence to safety guidelines

## 🛡️ Security & Compliance

### **API Key Security**

#### **Secure Storage**
- **Encryption**: API keys encrypted at rest
- **Access Control**: Limited access to provider credentials
- **Audit Logging**: Complete access and usage logging
- **Key Rotation**: Support for regular key updates

#### **Access Management**
- **Organization Level**: Provider access at organization level
- **User Permissions**: Role-based access control
- **Session Management**: Secure session handling
- **Multi-factor Authentication**: Enhanced security for sensitive operations

### **Data Protection**

#### **Data Privacy**
- **No Storage**: ai+me doesn't store your API keys
- **Secure Transmission**: All API calls use HTTPS
- **Data Minimization**: Only necessary data is transmitted
- **Compliance**: Support for GDPR, SOC 2, and other standards

#### **Enterprise Features**
- **Private Endpoints**: Support for private network connections
- **Data Residency**: Regional data storage options
- **Compliance Reporting**: Detailed compliance documentation
- **Security Audits**: Regular security assessments

## 🔄 Provider Lifecycle Management

### **Setup Phase**

#### **Initial Configuration**
- **Provider Selection**: Choose appropriate provider for your needs
- **Credential Setup**: Configure API keys and endpoints
- **Model Selection**: Choose suitable models for your use case
- **Testing**: Validate configuration and connectivity

#### **Integration Testing**
- **Connectivity Test**: Verify API endpoint accessibility
- **Authentication Test**: Validate API key functionality
- **Model Test**: Test specific model capabilities
- **Performance Test**: Assess response times and reliability

### **Production Phase**

#### **Active Monitoring**
- **Real-time Monitoring**: Track provider performance
- **Alert Management**: Set up alerts for issues
- **Performance Optimization**: Optimize for cost and speed
- **Regular Maintenance**: Periodic configuration reviews

#### **Scaling & Optimization**
- **Load Management**: Handle increased request volumes
- **Cost Optimization**: Minimize API usage costs
- **Performance Tuning**: Optimize response times
- **Capacity Planning**: Plan for future growth

### **Maintenance Phase**

#### **Regular Updates**
- **Key Rotation**: Periodic API key updates
- **Model Updates**: Update to newer model versions
- **Configuration Reviews**: Regular settings audits
- **Security Updates**: Apply security patches and updates

#### **Troubleshooting**
- **Issue Detection**: Identify provider problems
- **Root Cause Analysis**: Understand issue causes
- **Resolution**: Fix configuration or connectivity issues
- **Prevention**: Implement measures to prevent future issues

## 🆘 Troubleshooting Common Issues

### **Configuration Issues**

#### **API Key Problems**
- **Invalid Format**: Ensure API key follows correct format
- **Expired Key**: Check if API key is still valid
- **Insufficient Permissions**: Verify API key has required permissions
- **Rate Limiting**: Check for API usage limits

#### **Endpoint Issues**
- **Invalid URL**: Verify endpoint URL format
- **Network Connectivity**: Check network access to endpoint
- **SSL/TLS Issues**: Ensure proper HTTPS configuration
- **DNS Resolution**: Verify domain name resolution

### **Performance Issues**

#### **Response Time Problems**
- **Network Latency**: Check network connectivity
- **Provider Load**: Monitor provider service status
- **Request Size**: Optimize request payload size
- **Model Selection**: Choose appropriate model for task

#### **Error Handling**
- **Timeout Errors**: Increase timeout settings
- **Rate Limit Errors**: Implement request throttling
- **Authentication Errors**: Verify API credentials
- **Model Errors**: Check model availability and compatibility

### **Integration Issues**

#### **Connectivity Problems**
- **Firewall Rules**: Check local firewall configuration
- **Proxy Settings**: Configure proxy if required
- **SSL Certificates**: Verify SSL certificate validity
- **Network Policies**: Check corporate network policies

#### **Authentication Issues**
- **API Key Format**: Ensure correct API key format
- **Permissions**: Verify API key permissions
- **Account Status**: Check account activation status
- **Billing**: Ensure account has sufficient credits

## 📈 Best Practices for Model Provider Management

### **Provider Selection**

#### **Use Case Alignment**
- **Security Testing**: Choose providers with strong security capabilities
- **Performance Requirements**: Select providers with appropriate speed
- **Cost Considerations**: Balance cost with performance needs
- **Compliance Needs**: Ensure providers meet regulatory requirements

#### **Multi-Provider Strategy**
- **Redundancy**: Use multiple providers for high availability
- **Load Distribution**: Distribute load across providers
- **Cost Optimization**: Use different providers for different tasks
- **Geographic Distribution**: Choose providers for regional compliance

### **Configuration Management**

#### **Security Best Practices**
- **Regular Key Rotation**: Update API keys periodically
- **Access Monitoring**: Monitor provider usage and access
- **Credential Protection**: Secure API key storage and transmission
- **Audit Logging**: Maintain complete audit trails

#### **Performance Optimization**
- **Model Selection**: Choose appropriate models for tasks
- **Request Optimization**: Minimize request payload size
- **Caching**: Implement appropriate caching strategies
- **Load Balancing**: Distribute requests across providers

### **Monitoring & Maintenance**

#### **Proactive Monitoring**
- **Health Checks**: Regular provider health monitoring
- **Performance Tracking**: Monitor response times and success rates
- **Cost Monitoring**: Track API usage and costs
- **Alert Management**: Set up alerts for issues

#### **Regular Maintenance**
- **Configuration Reviews**: Periodic settings audits
- **Security Updates**: Apply security patches and updates
- **Performance Optimization**: Continuously optimize performance
- **Documentation**: Maintain up-to-date configuration documentation

## 📚 Next Steps

Now that you understand model providers in ai+me, you can:

1. **Set Up Your First Provider**: Configure OpenAI or Azure OpenAI
2. **Test Your Configuration**: Validate provider connectivity
3. **Create Experiments**: Use providers for security testing
4. **Monitor Performance**: Track usage and optimize costs
5. **Scale Your Setup**: Add multiple providers for redundancy

For more detailed information, explore our guides on:
- [🏢 Projects & Project Management](./projects.mdx)
- [🧪 Experiments & Testing](./experiments.mdx)
- [🔥 Firewall & Security](./firewall.mdx)
- [⚖️ LLM-as-a-Judge](./llm_as_a_judge.mdx)
