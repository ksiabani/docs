{"/community":{"title":"🌍 Join the AIandMe Community","data":{"":"The AIandMe Community is the perfect place to:✅ Ask questions and get support from other developers.\n✅ Share your AI security experiences and best practices.\n✅ Stay updated on the latest AIandMe features and improvements.","-where-to-connect#📢 Where to Connect?":"🔹 Discord → Chat with AI enthusiasts & developers.\n🔹 GitHub → Contribute, report issues, and suggest features.\n🔹 AIandBeers Meetups → Join live discussions and webinars.","-get-involved#🔥 Get Involved":"💡 Found a bug or have a feature request? → Open an issue on GitHub.\n📖 Want to contribute? → Check out our open-source projects and submit pull requests.\n🔎 Looking for AI insights? → Join our community discussions and AI talks.💬 Have questions? Drop by our Discord and say hi! 🚀"}},"/":{"title":"AIandMe Platform Documentation","data":{"":"Welcome to the AIandMe documentation! This guide will help you set up, integrate, and use AIandMe to keep your AI applications safe, accurate, and compliant.AIandMe is built for developers, AI teams, and businesses who care about trustworthy and ethical AI deployment. Whether you're in development, production, or post-deployment, our tools help you test, secure, and monitor your AI system.","what-is-aiandme#What is AIandMe?":"AIandMe is a platform designed to test and secure AI systems at different stages. It consists of three key components:","1-contextual-penetration-testing-development-phase#1. Contextual Penetration Testing (Development Phase)":"Catch vulnerabilities before they become a problem. AIandMe runs automated adversarial tests to identify security gaps in your AI system.🔹 Synthetic Adversarial Prompts – Generates test prompts to uncover weaknesses.\n🔹 LLM-as-a-Judge – Uses an AI evaluator to detect vulnerabilities.\n🔹 Iterative Refinement – Helps you fine-tune your model with real-world insights.","2️-real-time-protection-production-phase#2️. Real-Time Protection (Production Phase)":"Monitor and block risky AI behavior in real-time. AIandMe ensures your AI stays on track by preventing unwanted outputs.🔹 Optimized LLM Evaluator – Detects off-topic or unsafe prompts.\n🔹 Fine-Tuning Support – Uses penetration test insights to improve security over time.","3️-asynchronous-auditing-post-deployment#3️. Asynchronous Auditing (Post-Deployment)":"Keep your AI compliant and reliable even after deployment. AIandMe continuously audits logs and flags potential issues.🔹 Scheduled Audits – Scans user interactions for unexpected behavior.\n🔹 LLM-as-a-Judge – Applies AI-based evaluation techniques for better insights.\n🔹 Expert Review – Human experts analyze flagged issues to enhance security.","-why-use-aiandme#🔹 Why Use AIandMe?":"1️⃣ Minimize Risk → Avoid compliance, legal, and reputation risks.\n2️⃣ Improve AI Continuously → Keep refining your AI with real-world testing.\n3️⃣ Build User Trust → Block harmful responses and ensure ethical AI interactions.","-get-started#🚀 Get Started":"Want to start testing? Follow these quick steps:1️⃣ Sign Up – Create an AIandMe account.\n2️⃣ Choose a Plan – Pick the option that fits your needs.\n3️⃣ Connect Your AI – Link AIandMe to your GenAI application.\n4️⃣ Start Testing – Run penetration tests and monitor real-time AI behavior.","-need-help#📌 Need Help?":"🔗 Visit our Help Center\n📩 Contact Support"}},"/faqs":{"title":"Faqs","data":{"":""}}}